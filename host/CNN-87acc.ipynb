{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5e7bfd-f0c5-4107-9dd4-884ae90aae2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 14:57:35.275071: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-30 14:57:35.382612: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-30 14:57:36.162033: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-12-30 14:57:36.162191: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-12-30 14:57:36.162197: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cfc1062-c1b8-4efb-8a71-a4f349c789c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 07:28:20.953493: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-14 07:28:21.085333: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-14 07:28:21.916321: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-14 07:28:21.916380: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-14 07:28:21.916385: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (40000, 32, 32, 3), Validation data shape: (10000, 32, 32, 3)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                131136    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 420,586\n",
      "Trainable params: 419,690\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 07:28:26.304418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13598 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5\n",
      "2025-01-14 07:28:26.306775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13598 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:d8:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Split 10% of x_train and y_train for validation\n",
    "validation_split = 0.2\n",
    "val_size = int(validation_split * x_train.shape[0])\n",
    "x_val = x_train[:val_size]\n",
    "y_val = y_train[:val_size]\n",
    "x_train = x_train[val_size:]\n",
    "y_train = y_train[val_size:]\n",
    "print(f\"Training data shape: {x_train.shape}, Validation data shape: {x_val.shape}\")\n",
    "\n",
    "\n",
    "# Build the model\n",
    "model = models.Sequential()\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3),  activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3),activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279d1703-4ac4-4cf0-ae1b-46fc65d0c903",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 07:28:29.496423: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 29s 38ms/step - loss: 1.4357 - accuracy: 0.4835 - val_loss: 1.2575 - val_accuracy: 0.5666 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 1.0279 - accuracy: 0.6330 - val_loss: 1.1099 - val_accuracy: 0.6416 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.8669 - accuracy: 0.6967 - val_loss: 0.7923 - val_accuracy: 0.7300 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.7675 - accuracy: 0.7315 - val_loss: 0.7576 - val_accuracy: 0.7456 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.7002 - accuracy: 0.7551 - val_loss: 0.6479 - val_accuracy: 0.7771 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.6527 - accuracy: 0.7742 - val_loss: 0.7074 - val_accuracy: 0.7650 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.6000 - accuracy: 0.7887 - val_loss: 0.6501 - val_accuracy: 0.7816 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.5669 - accuracy: 0.8025 - val_loss: 0.6346 - val_accuracy: 0.7891 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.5408 - accuracy: 0.8131 - val_loss: 0.5945 - val_accuracy: 0.7952 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.5189 - accuracy: 0.8195 - val_loss: 0.6492 - val_accuracy: 0.7908 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "625/625 [==============================] - 25s 41ms/step - loss: 0.4955 - accuracy: 0.8286 - val_loss: 0.5452 - val_accuracy: 0.8190 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.4710 - accuracy: 0.8353 - val_loss: 0.6543 - val_accuracy: 0.7884 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "625/625 [==============================] - 25s 41ms/step - loss: 0.4523 - accuracy: 0.8417 - val_loss: 0.5686 - val_accuracy: 0.8102 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.4374 - accuracy: 0.8499 - val_loss: 0.5462 - val_accuracy: 0.8285 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.4016 - accuracy: 0.8608 - val_loss: 0.5765 - val_accuracy: 0.8136 - lr: 8.0000e-04\n",
      "Epoch 16/100\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.3885 - accuracy: 0.8644 - val_loss: 0.4978 - val_accuracy: 0.8368 - lr: 8.0000e-04\n",
      "Epoch 17/100\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.3766 - accuracy: 0.8681 - val_loss: 0.4888 - val_accuracy: 0.8428 - lr: 8.0000e-04\n",
      "Epoch 18/100\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.3642 - accuracy: 0.8718 - val_loss: 0.5616 - val_accuracy: 0.8283 - lr: 8.0000e-04\n",
      "Epoch 19/100\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.3579 - accuracy: 0.8733 - val_loss: 0.5994 - val_accuracy: 0.8151 - lr: 8.0000e-04\n",
      "Epoch 20/100\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.3442 - accuracy: 0.8795 - val_loss: 0.5654 - val_accuracy: 0.8243 - lr: 8.0000e-04\n",
      "Epoch 21/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.3192 - accuracy: 0.8884 - val_loss: 0.4230 - val_accuracy: 0.8612 - lr: 6.4000e-04\n",
      "Epoch 22/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.3101 - accuracy: 0.8914 - val_loss: 0.4618 - val_accuracy: 0.8540 - lr: 6.4000e-04\n",
      "Epoch 23/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.3029 - accuracy: 0.8941 - val_loss: 0.4830 - val_accuracy: 0.8513 - lr: 6.4000e-04\n",
      "Epoch 24/100\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.2937 - accuracy: 0.8982 - val_loss: 0.4850 - val_accuracy: 0.8489 - lr: 6.4000e-04\n",
      "Epoch 25/100\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.2742 - accuracy: 0.9040 - val_loss: 0.4690 - val_accuracy: 0.8490 - lr: 5.1200e-04\n",
      "Epoch 26/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.2664 - accuracy: 0.9050 - val_loss: 0.4042 - val_accuracy: 0.8714 - lr: 5.1200e-04\n",
      "Epoch 27/100\n",
      "625/625 [==============================] - 28s 45ms/step - loss: 0.2654 - accuracy: 0.9063 - val_loss: 0.4328 - val_accuracy: 0.8687 - lr: 5.1200e-04\n",
      "Epoch 28/100\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.2514 - accuracy: 0.9111 - val_loss: 0.4573 - val_accuracy: 0.8610 - lr: 5.1200e-04\n",
      "Epoch 29/100\n",
      "625/625 [==============================] - 22s 36ms/step - loss: 0.2494 - accuracy: 0.9108 - val_loss: 0.4450 - val_accuracy: 0.8616 - lr: 5.1200e-04\n",
      "Epoch 30/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.2342 - accuracy: 0.9173 - val_loss: 0.4148 - val_accuracy: 0.8744 - lr: 4.0960e-04\n",
      "Epoch 31/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.2297 - accuracy: 0.9194 - val_loss: 0.4218 - val_accuracy: 0.8748 - lr: 4.0960e-04\n",
      "Epoch 32/100\n",
      "625/625 [==============================] - 19s 30ms/step - loss: 0.2244 - accuracy: 0.9208 - val_loss: 0.4479 - val_accuracy: 0.8666 - lr: 4.0960e-04\n",
      "Epoch 33/100\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.2096 - accuracy: 0.9258 - val_loss: 0.4302 - val_accuracy: 0.8729 - lr: 3.2768e-04\n",
      "Epoch 34/100\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.2025 - accuracy: 0.9281 - val_loss: 0.4362 - val_accuracy: 0.8738 - lr: 3.2768e-04\n",
      "Epoch 35/100\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.2015 - accuracy: 0.9285 - val_loss: 0.4236 - val_accuracy: 0.8771 - lr: 3.2768e-04\n",
      "Epoch 36/100\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.1905 - accuracy: 0.9319 - val_loss: 0.4193 - val_accuracy: 0.8775 - lr: 2.6214e-04\n",
      "Epoch 37/100\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.1872 - accuracy: 0.9339 - val_loss: 0.4452 - val_accuracy: 0.8707 - lr: 2.6214e-04\n",
      "Epoch 38/100\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.1833 - accuracy: 0.9349 - val_loss: 0.4551 - val_accuracy: 0.8708 - lr: 2.6214e-04\n",
      "Epoch 39/100\n",
      "625/625 [==============================] - 22s 36ms/step - loss: 0.1753 - accuracy: 0.9377 - val_loss: 0.4161 - val_accuracy: 0.8817 - lr: 2.0972e-04\n",
      "Epoch 40/100\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.1713 - accuracy: 0.9398 - val_loss: 0.4153 - val_accuracy: 0.8812 - lr: 2.0972e-04\n",
      "Epoch 41/100\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.1684 - accuracy: 0.9401 - val_loss: 0.4578 - val_accuracy: 0.8728 - lr: 2.0972e-04\n",
      "Epoch 42/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.1649 - accuracy: 0.9409 - val_loss: 0.4157 - val_accuracy: 0.8804 - lr: 1.6777e-04\n",
      "Epoch 43/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.1604 - accuracy: 0.9417 - val_loss: 0.4265 - val_accuracy: 0.8792 - lr: 1.6777e-04\n",
      "Epoch 44/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.1582 - accuracy: 0.9427 - val_loss: 0.4425 - val_accuracy: 0.8785 - lr: 1.6777e-04\n",
      "Epoch 45/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.1524 - accuracy: 0.9467 - val_loss: 0.4327 - val_accuracy: 0.8813 - lr: 1.3422e-04\n",
      "Epoch 46/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.1543 - accuracy: 0.9456 - val_loss: 0.4410 - val_accuracy: 0.8763 - lr: 1.3422e-04\n",
      "Epoch 47/100\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.1510 - accuracy: 0.9466 - val_loss: 0.4217 - val_accuracy: 0.8804 - lr: 1.3422e-04\n",
      "Epoch 48/100\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.1467 - accuracy: 0.9475 - val_loss: 0.4244 - val_accuracy: 0.8839 - lr: 1.0737e-04\n",
      "Epoch 49/100\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.1440 - accuracy: 0.9489 - val_loss: 0.4329 - val_accuracy: 0.8806 - lr: 1.0737e-04\n",
      "Epoch 50/100\n",
      "625/625 [==============================] - 22s 36ms/step - loss: 0.1460 - accuracy: 0.9488 - val_loss: 0.4213 - val_accuracy: 0.8819 - lr: 1.0737e-04\n",
      "Epoch 51/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.1367 - accuracy: 0.9520 - val_loss: 0.4351 - val_accuracy: 0.8810 - lr: 8.5899e-05\n",
      "Epoch 52/100\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.1348 - accuracy: 0.9527 - val_loss: 0.4271 - val_accuracy: 0.8850 - lr: 8.5899e-05\n",
      "Epoch 53/100\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.1348 - accuracy: 0.9521 - val_loss: 0.4334 - val_accuracy: 0.8826 - lr: 8.5899e-05\n",
      "Epoch 54/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.1372 - accuracy: 0.9509 - val_loss: 0.4306 - val_accuracy: 0.8840 - lr: 6.8719e-05\n",
      "Epoch 55/100\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.1318 - accuracy: 0.9533 - val_loss: 0.4315 - val_accuracy: 0.8826 - lr: 6.8719e-05\n",
      "Epoch 56/100\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.1306 - accuracy: 0.9538 - val_loss: 0.4382 - val_accuracy: 0.8820 - lr: 6.8719e-05\n",
      "Epoch 57/100\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.1306 - accuracy: 0.9525 - val_loss: 0.4298 - val_accuracy: 0.8827 - lr: 5.4976e-05\n",
      "Epoch 58/100\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.1276 - accuracy: 0.9547 - val_loss: 0.4222 - val_accuracy: 0.8862 - lr: 5.4976e-05\n",
      "Epoch 59/100\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.1238 - accuracy: 0.9572 - val_loss: 0.4271 - val_accuracy: 0.8850 - lr: 5.4976e-05\n",
      "Epoch 60/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.1245 - accuracy: 0.9559 - val_loss: 0.4292 - val_accuracy: 0.8856 - lr: 4.3980e-05\n",
      "Epoch 61/100\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.1285 - accuracy: 0.9553 - val_loss: 0.4331 - val_accuracy: 0.8835 - lr: 4.3980e-05\n",
      "Epoch 62/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.1238 - accuracy: 0.9556 - val_loss: 0.4331 - val_accuracy: 0.8840 - lr: 4.3980e-05\n",
      "Epoch 63/100\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.1228 - accuracy: 0.9567 - val_loss: 0.4298 - val_accuracy: 0.8843 - lr: 3.5184e-05\n",
      "Epoch 64/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.1225 - accuracy: 0.9571 - val_loss: 0.4275 - val_accuracy: 0.8847 - lr: 3.5184e-05\n",
      "Epoch 65/100\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.1222 - accuracy: 0.9566 - val_loss: 0.4280 - val_accuracy: 0.8846 - lr: 3.5184e-05\n",
      "Epoch 66/100\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.1198 - accuracy: 0.9582 - val_loss: 0.4307 - val_accuracy: 0.8837 - lr: 2.8147e-05\n",
      "Epoch 67/100\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.1192 - accuracy: 0.9585 - val_loss: 0.4304 - val_accuracy: 0.8838 - lr: 2.8147e-05\n",
      "Epoch 68/100\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.1198 - accuracy: 0.9577 - val_loss: 0.4351 - val_accuracy: 0.8827 - lr: 2.8147e-05\n",
      "Epoch 69/100\n",
      "625/625 [==============================] - 22s 36ms/step - loss: 0.1213 - accuracy: 0.9570 - val_loss: 0.4292 - val_accuracy: 0.8852 - lr: 2.2518e-05\n",
      "Epoch 70/100\n",
      "625/625 [==============================] - 22s 36ms/step - loss: 0.1227 - accuracy: 0.9570 - val_loss: 0.4296 - val_accuracy: 0.8846 - lr: 2.2518e-05\n",
      "Epoch 71/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.1214 - accuracy: 0.9563 - val_loss: 0.4346 - val_accuracy: 0.8839 - lr: 2.2518e-05\n",
      "Epoch 72/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.1169 - accuracy: 0.9588 - val_loss: 0.4281 - val_accuracy: 0.8844 - lr: 1.8014e-05\n",
      "Epoch 73/100\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.1179 - accuracy: 0.9587 - val_loss: 0.4307 - val_accuracy: 0.8841 - lr: 1.8014e-05\n",
      "Epoch 74/100\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.1173 - accuracy: 0.9590 - val_loss: 0.4280 - val_accuracy: 0.8846 - lr: 1.8014e-05\n",
      "Epoch 75/100\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.1185 - accuracy: 0.9575 - val_loss: 0.4304 - val_accuracy: 0.8852 - lr: 1.4412e-05\n",
      "Epoch 76/100\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.1211 - accuracy: 0.9574 - val_loss: 0.4297 - val_accuracy: 0.8855 - lr: 1.4412e-05\n",
      "Epoch 77/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.1164 - accuracy: 0.9588 - val_loss: 0.4317 - val_accuracy: 0.8847 - lr: 1.4412e-05\n",
      "Epoch 78/100\n",
      "625/625 [==============================] - 22s 36ms/step - loss: 0.1144 - accuracy: 0.9596 - val_loss: 0.4304 - val_accuracy: 0.8853 - lr: 1.1529e-05\n",
      "Epoch 79/100\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.1127 - accuracy: 0.9599 - val_loss: 0.4296 - val_accuracy: 0.8850 - lr: 1.1529e-05\n",
      "Epoch 80/100\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.1191 - accuracy: 0.9578 - val_loss: 0.4289 - val_accuracy: 0.8855 - lr: 1.1529e-05\n",
      "Epoch 81/100\n",
      "625/625 [==============================] - 22s 36ms/step - loss: 0.1158 - accuracy: 0.9593 - val_loss: 0.4294 - val_accuracy: 0.8855 - lr: 9.2234e-06\n",
      "Epoch 82/100\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.1139 - accuracy: 0.9602 - val_loss: 0.4309 - val_accuracy: 0.8851 - lr: 9.2234e-06\n",
      "Epoch 83/100\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.1117 - accuracy: 0.9604 - val_loss: 0.4326 - val_accuracy: 0.8840 - lr: 9.2234e-06\n",
      "Epoch 84/100\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.1156 - accuracy: 0.9590 - val_loss: 0.4321 - val_accuracy: 0.8849 - lr: 7.3787e-06\n",
      "Epoch 85/100\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.1174 - accuracy: 0.9591 - val_loss: 0.4318 - val_accuracy: 0.8850 - lr: 7.3787e-06\n",
      "Epoch 86/100\n",
      "625/625 [==============================] - 25s 41ms/step - loss: 0.1153 - accuracy: 0.9592 - val_loss: 0.4324 - val_accuracy: 0.8852 - lr: 7.3787e-06\n",
      "Epoch 87/100\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.1107 - accuracy: 0.9604 - val_loss: 0.4307 - val_accuracy: 0.8856 - lr: 5.9030e-06\n",
      "Epoch 88/100\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.1156 - accuracy: 0.9582 - val_loss: 0.4318 - val_accuracy: 0.8865 - lr: 5.9030e-06\n",
      "Epoch 89/100\n",
      "625/625 [==============================] - 22s 36ms/step - loss: 0.1102 - accuracy: 0.9612 - val_loss: 0.4322 - val_accuracy: 0.8852 - lr: 5.9030e-06\n",
      "Epoch 90/100\n",
      "  7/625 [..............................] - ETA: 23s - loss: 0.1009 - accuracy: 0.9643"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=3, min_lr=1e-8)\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=64),\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=100,\n",
    "    callbacks=[reduce_lr]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7235c332-142d-4abd-a944-bd778272dc62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model (architecture + weights + optimizer state)\n",
    "model.save('87_LITE_rgb.h5')  # Saves as HDF5 format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15f8cee7-1f24-4396-82e1-88e44f9ccde8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.5094 - accuracy: 0.8630 - 2s/epoch - 6ms/step\n",
      "Test accuracy: 86.30%\n",
      "params: 370402\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_54 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 32, 32, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 32, 32, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 16, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 16, 16, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 16, 16, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 8, 8, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 8, 8, 120)         69240     \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 8, 8, 120)        480       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 8, 8, 120)         129720    \n",
      "                                                                 \n",
      " batch_normalization_59 (Bat  (None, 8, 8, 120)        480       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 4, 4, 120)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 1920)              0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 64)                122944    \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 120)               7800      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 10)                1210      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 370,402\n",
      "Trainable params: 369,602\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc * 100:.2f}%\")\n",
    "print(\"params:\",model.count_params())\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d97ae4d-1858-4326-9cda-dc1439cd4a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
